# 微服务架构实践

> 从单体应用到微服务架构的完整实践指南

## 📚 目录

- [微服务设计原则](#微服务设计原则)
- [服务拆分策略](#服务拆分策略)
- [API网关架构](#API网关架构)
- [服务发现与注册](#服务发现与注册)
- [分布式数据管理](#分布式数据管理)
- [服务间通信模式](#服务间通信模式)
- [微服务治理](#微服务治理)
- [实战项目实施](#实战项目实施)

---

## 微服务设计原则

### 🎯 **微服务核心原则**

#### 单一职责原则
```
每个微服务应该只有一个改变的理由
- 业务职责单一
- 数据访问独立
- 部署单元独立
- 团队责任明确
```

#### 去中心化治理
```
避免企业级服务总线 (ESB)
- 智能端点，愚笨管道
- 服务自治决策
- 技术栈多样化
- 独立的数据管理
```

#### 容错设计
```
拥抱失败，设计容错
- 服务降级
- 熔断机制
- 超时重试
- 监控告警
```

### 🏗️ **微服务边界定义**

#### 业务能力映射
```yaml
# 电商平台业务能力分解
business_capabilities:
  user_management:
    services:
      - user-service
      - auth-service
      - profile-service
    data_ownership:
      - users
      - user_profiles
      - authentication_tokens
    
  product_catalog:
    services:
      - product-service
      - inventory-service
      - category-service
    data_ownership:
      - products
      - inventory
      - categories
    
  order_management:
    services:
      - order-service
      - cart-service
      - shipping-service
    data_ownership:
      - orders
      - shopping_carts
      - shipments
    
  payment_processing:
    services:
      - payment-service
      - billing-service
      - refund-service
    data_ownership:
      - payments
      - billing_records
      - refunds
```

#### 数据一致性边界
```go
// 聚合根定义
package domain

// Order聚合根
type Order struct {
    ID          string
    UserID      string
    Items       []OrderItem
    Status      OrderStatus
    TotalAmount decimal.Decimal
    CreatedAt   time.Time
    UpdatedAt   time.Time
}

// OrderItem值对象
type OrderItem struct {
    ProductID string
    Quantity  int
    Price     decimal.Decimal
}

// 业务规则在聚合内部维护
func (o *Order) AddItem(productID string, quantity int, price decimal.Decimal) error {
    if o.Status != OrderStatusDraft {
        return errors.New("cannot modify confirmed order")
    }
    
    // 检查是否已存在该商品
    for i, item := range o.Items {
        if item.ProductID == productID {
            o.Items[i].Quantity += quantity
            o.calculateTotal()
            return nil
        }
    }
    
    // 添加新商品
    o.Items = append(o.Items, OrderItem{
        ProductID: productID,
        Quantity:  quantity,
        Price:     price,
    })
    
    o.calculateTotal()
    return nil
}

func (o *Order) calculateTotal() {
    total := decimal.Zero
    for _, item := range o.Items {
        itemTotal := item.Price.Mul(decimal.NewFromInt(int64(item.Quantity)))
        total = total.Add(itemTotal)
    }
    o.TotalAmount = total
}
```

---

## 服务拆分策略

### 📊 **领域驱动拆分法**

#### 限界上下文识别
```
用户上下文 (User Context)
├── 身份认证 (Authentication)
├── 用户画像 (User Profile)
└── 权限管理 (Authorization)

商品上下文 (Product Context)
├── 商品信息 (Product Information)
├── 库存管理 (Inventory Management)
└── 价格策略 (Pricing Strategy)

订单上下文 (Order Context)
├── 购物车 (Shopping Cart)
├── 订单处理 (Order Processing)
└── 支付流程 (Payment Flow)
```

#### 服务拆分实施步骤
```bash
# 步骤1: 识别业务边界
./scripts/analyze-business-boundaries.sh

# 步骤2: 分析数据依赖
./scripts/analyze-data-dependencies.sh

# 步骤3: 评估团队结构
./scripts/analyze-team-structure.sh

# 步骤4: 制定拆分计划
./scripts/create-migration-plan.sh
```

### 🔄 **拆分策略实现**

#### 绞杀者模式 (Strangler Fig Pattern)
```yaml
# Phase 1: 路由层引入
apiVersion: networking.istio.io/v1beta1
kind: VirtualService
metadata:
  name: user-migration
spec:
  hosts:
  - api.company.com
  http:
  # 新功能路由到微服务
  - match:
    - uri:
        prefix: /api/v2/users
    route:
    - destination:
        host: user-service
        port:
          number: 8080
      weight: 100
  
  # 旧功能继续使用单体应用
  - match:
    - uri:
        prefix: /api/v1/users
    route:
    - destination:
        host: monolith-app
        port:
          number: 8080
      weight: 100
---
# Phase 2: 逐步迁移流量
apiVersion: networking.istio.io/v1beta1
kind: VirtualService
metadata:
  name: user-migration-canary
spec:
  hosts:
  - api.company.com
  http:
  - match:
    - uri:
        prefix: /api/users
    route:
    - destination:
        host: user-service
        port:
          number: 8080
      weight: 20  # 20%流量到新服务
    - destination:
        host: monolith-app
        port:
          number: 8080
      weight: 80  # 80%流量到单体应用
```

#### 数据同步策略
```go
// 双写模式实现
package migration

import (
    "context"
    "log"
)

type DualWriteUserRepository struct {
    legacyRepo UserRepository
    newRepo    UserRepository
    syncMode   SyncMode
}

type SyncMode int

const (
    SyncModeAsync SyncMode = iota
    SyncModeSync
)

func (d *DualWriteUserRepository) CreateUser(ctx context.Context, user *User) error {
    // 主写入到新系统
    if err := d.newRepo.CreateUser(ctx, user); err != nil {
        return err
    }
    
    // 同步到旧系统
    switch d.syncMode {
    case SyncModeSync:
        if err := d.legacyRepo.CreateUser(ctx, user); err != nil {
            log.Printf("Failed to sync user to legacy system: %v", err)
            // 可以选择回滚新系统或继续
            return err
        }
    case SyncModeAsync:
        go func() {
            if err := d.legacyRepo.CreateUser(context.Background(), user); err != nil {
                log.Printf("Failed to async sync user to legacy system: %v", err)
                // 发送到死信队列或重试队列
                d.handleSyncFailure(user, err)
            }
        }()
    }
    
    return nil
}

func (d *DualWriteUserRepository) handleSyncFailure(user *User, err error) {
    // 实现重试逻辑或将失败记录发送到消息队列
    event := &SyncFailureEvent{
        Entity: "user",
        ID:     user.ID,
        Data:   user,
        Error:  err.Error(),
    }
    
    // 发送到重试队列
    retryQueue.Publish(event)
}
```

---

## API网关架构

### 🌐 **网关功能设计**

#### 核心功能模块
```
API Gateway
├── 路由管理 (Routing)
├── 负载均衡 (Load Balancing)
├── 认证授权 (Authentication & Authorization)
├── 限流熔断 (Rate Limiting & Circuit Breaking)
├── 协议转换 (Protocol Translation)
├── 监控日志 (Monitoring & Logging)
├── 缓存策略 (Caching)
└── API版本管理 (API Versioning)
```

#### Kong网关配置
```yaml
# Kong Gateway配置
apiVersion: v1
kind: ConfigMap
metadata:
  name: kong-config
data:
  kong.yaml: |
    _format_version: "3.0"
    
    services:
    - name: user-service
      url: http://user-service:8080
      plugins:
      - name: jwt
        config:
          secret_is_base64: false
      - name: rate-limiting
        config:
          minute: 100
          hour: 1000
    
    - name: product-service
      url: http://product-service:8080
      plugins:
      - name: cors
        config:
          origins:
          - "*"
          methods:
          - GET
          - POST
          - PUT
          - DELETE
    
    routes:
    - name: user-routes
      service: user-service
      paths:
      - /api/users
      - /api/auth
      strip_path: false
    
    - name: product-routes
      service: product-service
      paths:
      - /api/products
      - /api/inventory
      strip_path: false
    
    consumers:
    - username: mobile-app
      keyauth_credentials:
      - key: mobile-app-key-2023
    
    - username: web-app
      jwt_credentials:
      - key: web-app-jwt
        secret: web-app-secret-2023
    
    plugins:
    - name: prometheus
      config:
        per_consumer: true
        status_code_metrics: true
        latency_metrics: true
        bandwidth_metrics: true
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: kong-gateway
spec:
  replicas: 3
  selector:
    matchLabels:
      app: kong-gateway
  template:
    metadata:
      labels:
        app: kong-gateway
    spec:
      containers:
      - name: kong
        image: kong:3.4
        ports:
        - containerPort: 8000
        - containerPort: 8001
        - containerPort: 8443
        - containerPort: 8444
        env:
        - name: KONG_DATABASE
          value: "off"
        - name: KONG_DECLARATIVE_CONFIG
          value: "/kong/kong.yaml"
        - name: KONG_PROXY_ACCESS_LOG
          value: "/dev/stdout"
        - name: KONG_ADMIN_ACCESS_LOG
          value: "/dev/stdout"
        - name: KONG_PROXY_ERROR_LOG
          value: "/dev/stderr"
        - name: KONG_ADMIN_ERROR_LOG
          value: "/dev/stderr"
        - name: KONG_ADMIN_LISTEN
          value: "0.0.0.0:8001"
        volumeMounts:
        - name: kong-config
          mountPath: /kong
      volumes:
      - name: kong-config
        configMap:
          name: kong-config
```

#### 自定义网关实现
```go
// 简化的API网关实现
package gateway

import (
    "context"
    "fmt"
    "net/http"
    "net/http/httputil"
    "net/url"
    "strings"
    "time"
    
    "github.com/gin-gonic/gin"
    "golang.org/x/time/rate"
)

type Gateway struct {
    router      *gin.Engine
    services    map[string]*ServiceConfig
    rateLimiter *rate.Limiter
    auth        AuthService
    metrics     MetricsCollector
}

type ServiceConfig struct {
    Name     string
    BaseURL  *url.URL
    HealthCheck string
    Timeout  time.Duration
    Retries  int
}

func NewGateway(services map[string]*ServiceConfig) *Gateway {
    gw := &Gateway{
        router:      gin.New(),
        services:    services,
        rateLimiter: rate.NewLimiter(rate.Limit(1000), 100), // 1000 RPS with burst of 100
        auth:        NewJWTAuthService(),
        metrics:     NewPrometheusMetrics(),
    }
    
    gw.setupMiddleware()
    gw.setupRoutes()
    
    return gw
}

func (gw *Gateway) setupMiddleware() {
    // 日志中间件
    gw.router.Use(gin.LoggerWithConfig(gin.LoggerConfig{
        Formatter: func(param gin.LogFormatterParams) string {
            return fmt.Sprintf("%s - [%s] \"%s %s %s %d %s \"%s\" %s\"\n",
                param.ClientIP,
                param.TimeStamp.Format(time.RFC1123),
                param.Method,
                param.Path,
                param.Request.Proto,
                param.StatusCode,
                param.Latency,
                param.Request.UserAgent(),
                param.ErrorMessage,
            )
        },
    }))
    
    // 恢复中间件
    gw.router.Use(gin.Recovery())
    
    // CORS中间件
    gw.router.Use(func(c *gin.Context) {
        c.Header("Access-Control-Allow-Origin", "*")
        c.Header("Access-Control-Allow-Methods", "GET, POST, PUT, DELETE, OPTIONS")
        c.Header("Access-Control-Allow-Headers", "Origin, Content-Type, Authorization")
        
        if c.Request.Method == "OPTIONS" {
            c.AbortWithStatus(204)
            return
        }
        
        c.Next()
    })
    
    // 限流中间件
    gw.router.Use(gw.rateLimitMiddleware())
    
    // 认证中间件
    gw.router.Use(gw.authMiddleware())
    
    // 指标收集中间件
    gw.router.Use(gw.metricsMiddleware())
}

func (gw *Gateway) rateLimitMiddleware() gin.HandlerFunc {
    return func(c *gin.Context) {
        if !gw.rateLimiter.Allow() {
            c.JSON(http.StatusTooManyRequests, gin.H{
                "error": "Rate limit exceeded",
            })
            c.Abort()
            return
        }
        c.Next()
    }
}

func (gw *Gateway) authMiddleware() gin.HandlerFunc {
    return func(c *gin.Context) {
        // 跳过健康检查和公开端点
        if strings.HasPrefix(c.Request.URL.Path, "/health") ||
           strings.HasPrefix(c.Request.URL.Path, "/api/public") {
            c.Next()
            return
        }
        
        authHeader := c.GetHeader("Authorization")
        if authHeader == "" {
            c.JSON(http.StatusUnauthorized, gin.H{
                "error": "Authorization header required",
            })
            c.Abort()
            return
        }
        
        token := strings.TrimPrefix(authHeader, "Bearer ")
        claims, err := gw.auth.ValidateToken(token)
        if err != nil {
            c.JSON(http.StatusUnauthorized, gin.H{
                "error": "Invalid token",
            })
            c.Abort()
            return
        }
        
        c.Set("user_claims", claims)
        c.Next()
    }
}

func (gw *Gateway) metricsMiddleware() gin.HandlerFunc {
    return func(c *gin.Context) {
        start := time.Now()
        
        c.Next()
        
        duration := time.Since(start)
        gw.metrics.RecordRequest(c.Request.Method, c.FullPath(), c.Writer.Status(), duration)
    }
}

func (gw *Gateway) setupRoutes() {
    // 健康检查
    gw.router.GET("/health", func(c *gin.Context) {
        c.JSON(http.StatusOK, gin.H{
            "status": "healthy",
            "timestamp": time.Now(),
        })
    })
    
    // 动态路由到后端服务
    gw.router.Any("/api/*path", gw.proxyHandler)
}

func (gw *Gateway) proxyHandler(c *gin.Context) {
    path := c.Param("path")
    serviceName := gw.extractServiceName(path)
    
    service, exists := gw.services[serviceName]
    if !exists {
        c.JSON(http.StatusNotFound, gin.H{
            "error": "Service not found",
        })
        return
    }
    
    // 创建反向代理
    proxy := httputil.NewSingleHostReverseProxy(service.BaseURL)
    
    // 自定义错误处理
    proxy.ErrorHandler = func(w http.ResponseWriter, r *http.Request, err error) {
        c.JSON(http.StatusBadGateway, gin.H{
            "error": "Service unavailable",
            "service": serviceName,
        })
    }
    
    // 修改请求
    proxy.ModifyResponse = func(resp *http.Response) error {
        resp.Header.Set("X-Gateway", "custom-gateway")
        return nil
    }
    
    proxy.ServeHTTP(c.Writer, c.Request)
}

func (gw *Gateway) extractServiceName(path string) string {
    parts := strings.Split(strings.Trim(path, "/"), "/")
    if len(parts) > 0 {
        return parts[0]
    }
    return ""
}
```

---

## 服务发现与注册

### 🔍 **服务注册中心架构**

#### Consul集群部署
```yaml
# Consul集群配置
apiVersion: v1
kind: ConfigMap
metadata:
  name: consul-config
data:
  consul.json: |
    {
      "datacenter": "dc1",
      "data_dir": "/consul/data",
      "log_level": "INFO",
      "server": true,
      "bootstrap_expect": 3,
      "bind_addr": "0.0.0.0",
      "client_addr": "0.0.0.0",
      "retry_join": [
        "consul-0.consul-headless.default.svc.cluster.local",
        "consul-1.consul-headless.default.svc.cluster.local",
        "consul-2.consul-headless.default.svc.cluster.local"
      ],
      "ui_config": {
        "enabled": true
      },
      "connect": {
        "enabled": true
      },
      "acl": {
        "enabled": true,
        "default_policy": "deny",
        "enable_token_persistence": true
      }
    }
---
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: consul
spec:
  serviceName: consul-headless
  replicas: 3
  selector:
    matchLabels:
      app: consul
  template:
    metadata:
      labels:
        app: consul
    spec:
      containers:
      - name: consul
        image: consul:1.16.1
        ports:
        - containerPort: 8500
          name: ui
        - containerPort: 8300
          name: server
        - containerPort: 8301
          name: serf-lan
        - containerPort: 8302
          name: serf-wan
        - containerPort: 8600
          name: dns
        env:
        - name: POD_IP
          valueFrom:
            fieldRef:
              fieldPath: status.podIP
        - name: CONSUL_LOCAL_CONFIG
          valueFrom:
            configMapKeyRef:
              name: consul-config
              key: consul.json
        volumeMounts:
        - name: consul-data
          mountPath: /consul/data
        - name: consul-config
          mountPath: /consul/config
        livenessProbe:
          httpGet:
            path: /v1/status/leader
            port: 8500
          initialDelaySeconds: 30
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /v1/status/leader
            port: 8500
          initialDelaySeconds: 10
          periodSeconds: 5
      volumes:
      - name: consul-config
        configMap:
          name: consul-config
  volumeClaimTemplates:
  - metadata:
      name: consul-data
    spec:
      accessModes: ["ReadWriteOnce"]
      resources:
        requests:
          storage: 10Gi
```

#### 服务注册实现
```go
// 服务注册客户端
package discovery

import (
    "fmt"
    "log"
    "time"
    
    "github.com/hashicorp/consul/api"
)

type ServiceRegistry struct {
    client *api.Client
    config *ServiceConfig
}

type ServiceConfig struct {
    ID       string
    Name     string
    Tags     []string
    Address  string
    Port     int
    Health   HealthCheck
}

type HealthCheck struct {
    HTTP                           string
    Interval                       time.Duration
    Timeout                        time.Duration
    DeregisterCriticalServiceAfter time.Duration
}

func NewServiceRegistry(consulAddr string, config *ServiceConfig) (*ServiceRegistry, error) {
    consulConfig := api.DefaultConfig()
    consulConfig.Address = consulAddr
    
    client, err := api.NewClient(consulConfig)
    if err != nil {
        return nil, err
    }
    
    return &ServiceRegistry{
        client: client,
        config: config,
    }, nil
}

func (sr *ServiceRegistry) Register() error {
    registration := &api.AgentServiceRegistration{
        ID:      sr.config.ID,
        Name:    sr.config.Name,
        Tags:    sr.config.Tags,
        Address: sr.config.Address,
        Port:    sr.config.Port,
        Check: &api.AgentServiceCheck{
            HTTP:                           sr.config.Health.HTTP,
            Interval:                       sr.config.Health.Interval.String(),
            Timeout:                        sr.config.Health.Timeout.String(),
            DeregisterCriticalServiceAfter: sr.config.Health.DeregisterCriticalServiceAfter.String(),
        },
    }
    
    if err := sr.client.Agent().ServiceRegister(registration); err != nil {
        return fmt.Errorf("failed to register service: %w", err)
    }
    
    log.Printf("Service %s registered successfully", sr.config.Name)
    return nil
}

func (sr *ServiceRegistry) Deregister() error {
    if err := sr.client.Agent().ServiceDeregister(sr.config.ID); err != nil {
        return fmt.Errorf("failed to deregister service: %w", err)
    }
    
    log.Printf("Service %s deregistered successfully", sr.config.Name)
    return nil
}

// 服务发现客户端
type ServiceDiscovery struct {
    client *api.Client
    cache  map[string][]*ServiceInstance
}

type ServiceInstance struct {
    ID      string
    Address string
    Port    int
    Tags    []string
    Health  string
}

func NewServiceDiscovery(consulAddr string) (*ServiceDiscovery, error) {
    config := api.DefaultConfig()
    config.Address = consulAddr
    
    client, err := api.NewClient(config)
    if err != nil {
        return nil, err
    }
    
    return &ServiceDiscovery{
        client: client,
        cache:  make(map[string][]*ServiceInstance),
    }, nil
}

func (sd *ServiceDiscovery) GetHealthyInstances(serviceName string) ([]*ServiceInstance, error) {
    services, _, err := sd.client.Health().Service(serviceName, "", true, nil)
    if err != nil {
        return nil, fmt.Errorf("failed to get healthy instances: %w", err)
    }
    
    instances := make([]*ServiceInstance, 0, len(services))
    for _, service := range services {
        instances = append(instances, &ServiceInstance{
            ID:      service.Service.ID,
            Address: service.Service.Address,
            Port:    service.Service.Port,
            Tags:    service.Service.Tags,
            Health:  service.Checks.AggregatedStatus(),
        })
    }
    
    // 更新缓存
    sd.cache[serviceName] = instances
    
    return instances, nil
}

func (sd *ServiceDiscovery) WatchService(serviceName string, callback func([]*ServiceInstance)) {
    go func() {
        lastIndex := uint64(0)
        for {
            services, meta, err := sd.client.Health().Service(serviceName, "", true, &api.QueryOptions{
                WaitIndex: lastIndex,
                WaitTime:  30 * time.Second,
            })
            
            if err != nil {
                log.Printf("Error watching service %s: %v", serviceName, err)
                time.Sleep(5 * time.Second)
                continue
            }
            
            lastIndex = meta.LastIndex
            
            instances := make([]*ServiceInstance, 0, len(services))
            for _, service := range services {
                instances = append(instances, &ServiceInstance{
                    ID:      service.Service.ID,
                    Address: service.Service.Address,
                    Port:    service.Service.Port,
                    Tags:    service.Service.Tags,
                    Health:  service.Checks.AggregatedStatus(),
                })
            }
            
            callback(instances)
        }
    }()
}
```

#### 负载均衡实现
```go
// 负载均衡器
package loadbalancer

import (
    "errors"
    "math/rand"
    "sync"
    "sync/atomic"
    "time"
)

type LoadBalancer interface {
    SelectInstance(instances []*ServiceInstance) (*ServiceInstance, error)
}

// 轮询负载均衡
type RoundRobinLoadBalancer struct {
    counter uint64
}

func (lb *RoundRobinLoadBalancer) SelectInstance(instances []*ServiceInstance) (*ServiceInstance, error) {
    if len(instances) == 0 {
        return nil, errors.New("no available instances")
    }
    
    index := atomic.AddUint64(&lb.counter, 1) % uint64(len(instances))
    return instances[index], nil
}

// 加权轮询负载均衡
type WeightedRoundRobinLoadBalancer struct {
    mutex   sync.RWMutex
    weights map[string]*WeightedInstance
}

type WeightedInstance struct {
    Instance       *ServiceInstance
    Weight         int
    CurrentWeight  int
    EffectiveWeight int
}

func NewWeightedRoundRobinLoadBalancer() *WeightedRoundRobinLoadBalancer {
    return &WeightedRoundRobinLoadBalancer{
        weights: make(map[string]*WeightedInstance),
    }
}

func (lb *WeightedRoundRobinLoadBalancer) SelectInstance(instances []*ServiceInstance) (*ServiceInstance, error) {
    if len(instances) == 0 {
        return nil, errors.New("no available instances")
    }
    
    lb.mutex.Lock()
    defer lb.mutex.Unlock()
    
    // 更新权重信息
    lb.updateWeights(instances)
    
    // 选择权重最高的实例
    var selected *WeightedInstance
    totalWeight := 0
    
    for _, weighted := range lb.weights {
        weighted.CurrentWeight += weighted.EffectiveWeight
        totalWeight += weighted.EffectiveWeight
        
        if selected == nil || weighted.CurrentWeight > selected.CurrentWeight {
            selected = weighted
        }
    }
    
    if selected != nil {
        selected.CurrentWeight -= totalWeight
        return selected.Instance, nil
    }
    
    return nil, errors.New("no available instances")
}

func (lb *WeightedRoundRobinLoadBalancer) updateWeights(instances []*ServiceInstance) {
    currentInstances := make(map[string]bool)
    
    for _, instance := range instances {
        key := fmt.Sprintf("%s:%d", instance.Address, instance.Port)
        currentInstances[key] = true
        
        if _, exists := lb.weights[key]; !exists {
            weight := lb.extractWeight(instance.Tags)
            lb.weights[key] = &WeightedInstance{
                Instance:        instance,
                Weight:          weight,
                CurrentWeight:   0,
                EffectiveWeight: weight,
            }
        }
    }
    
    // 移除不存在的实例
    for key := range lb.weights {
        if !currentInstances[key] {
            delete(lb.weights, key)
        }
    }
}

func (lb *WeightedRoundRobinLoadBalancer) extractWeight(tags []string) int {
    for _, tag := range tags {
        if strings.HasPrefix(tag, "weight=") {
            if weight, err := strconv.Atoi(strings.TrimPrefix(tag, "weight=")); err == nil {
                return weight
            }
        }
    }
    return 1 // 默认权重
}

// 一致性哈希负载均衡
type ConsistentHashLoadBalancer struct {
    hash     hash.Hash32
    replicas int
    keys     []uint32
    hashMap  map[uint32]*ServiceInstance
    mutex    sync.RWMutex
}

func NewConsistentHashLoadBalancer(replicas int) *ConsistentHashLoadBalancer {
    return &ConsistentHashLoadBalancer{
        hash:     crc32.NewIEEE(),
        replicas: replicas,
        hashMap:  make(map[uint32]*ServiceInstance),
    }
}

func (lb *ConsistentHashLoadBalancer) SelectInstance(instances []*ServiceInstance) (*ServiceInstance, error) {
    if len(instances) == 0 {
        return nil, errors.New("no available instances")
    }
    
    lb.mutex.Lock()
    lb.updateHashRing(instances)
    lb.mutex.Unlock()
    
    // 使用请求的某个属性作为哈希键（这里简化处理）
    key := fmt.Sprintf("request-%d", time.Now().UnixNano())
    return lb.selectByKey(key), nil
}

func (lb *ConsistentHashLoadBalancer) selectByKey(key string) *ServiceInstance {
    lb.mutex.RLock()
    defer lb.mutex.RUnlock()
    
    if len(lb.keys) == 0 {
        return nil
    }
    
    lb.hash.Reset()
    lb.hash.Write([]byte(key))
    hashValue := lb.hash.Sum32()
    
    // 二分查找第一个大于等于hashValue的节点
    idx := sort.Search(len(lb.keys), func(i int) bool {
        return lb.keys[i] >= hashValue
    })
    
    if idx == len(lb.keys) {
        idx = 0
    }
    
    return lb.hashMap[lb.keys[idx]]
}
```

---

## 分布式数据管理

### 📊 **数据一致性模式**

#### Saga模式实现
```go
// Saga编排器
package saga

import (
    "context"
    "fmt"
    "log"
)

type SagaOrchestrator struct {
    steps []SagaStep
    state map[string]interface{}
}

type SagaStep interface {
    Execute(ctx context.Context, state map[string]interface{}) error
    Compensate(ctx context.Context, state map[string]interface{}) error
    Name() string
}

type SagaResult struct {
    Success bool
    Error   error
    Step    string
}

func NewSagaOrchestrator() *SagaOrchestrator {
    return &SagaOrchestrator{
        steps: make([]SagaStep, 0),
        state: make(map[string]interface{}),
    }
}

func (s *SagaOrchestrator) AddStep(step SagaStep) {
    s.steps = append(s.steps, step)
}

func (s *SagaOrchestrator) Execute(ctx context.Context) *SagaResult {
    executedSteps := make([]SagaStep, 0)
    
    // 执行所有步骤
    for _, step := range s.steps {
        log.Printf("Executing saga step: %s", step.Name())
        
        if err := step.Execute(ctx, s.state); err != nil {
            log.Printf("Saga step %s failed: %v", step.Name(), err)
            
            // 执行补偿操作
            s.compensate(ctx, executedSteps)
            
            return &SagaResult{
                Success: false,
                Error:   err,
                Step:    step.Name(),
            }
        }
        
        executedSteps = append(executedSteps, step)
    }
    
    return &SagaResult{
        Success: true,
    }
}

func (s *SagaOrchestrator) compensate(ctx context.Context, executedSteps []SagaStep) {
    // 逆序执行补偿操作
    for i := len(executedSteps) - 1; i >= 0; i-- {
        step := executedSteps[i]
        log.Printf("Compensating saga step: %s", step.Name())
        
        if err := step.Compensate(ctx, s.state); err != nil {
            log.Printf("Compensation failed for step %s: %v", step.Name(), err)
            // 补偿失败可能需要人工干预
        }
    }
}

// 订单创建Saga步骤
type CreateOrderStep struct {
    orderService OrderService
}

func (s *CreateOrderStep) Execute(ctx context.Context, state map[string]interface{}) error {
    orderRequest := state["order_request"].(*CreateOrderRequest)
    
    order, err := s.orderService.CreateOrder(ctx, orderRequest)
    if err != nil {
        return err
    }
    
    state["order_id"] = order.ID
    return nil
}

func (s *CreateOrderStep) Compensate(ctx context.Context, state map[string]interface{}) error {
    orderID := state["order_id"].(string)
    return s.orderService.CancelOrder(ctx, orderID)
}

func (s *CreateOrderStep) Name() string {
    return "CreateOrder"
}

// 扣减库存Saga步骤
type ReserveInventoryStep struct {
    inventoryService InventoryService
}

func (s *ReserveInventoryStep) Execute(ctx context.Context, state map[string]interface{}) error {
    orderRequest := state["order_request"].(*CreateOrderRequest)
    
    for _, item := range orderRequest.Items {
        if err := s.inventoryService.ReserveInventory(ctx, item.ProductID, item.Quantity); err != nil {
            return err
        }
    }
    
    return nil
}

func (s *ReserveInventoryStep) Compensate(ctx context.Context, state map[string]interface{}) error {
    orderRequest := state["order_request"].(*CreateOrderRequest)
    
    for _, item := range orderRequest.Items {
        if err := s.inventoryService.ReleaseReservation(ctx, item.ProductID, item.Quantity); err != nil {
            log.Printf("Failed to release inventory reservation: %v", err)
        }
    }
    
    return nil
}

func (s *ReserveInventoryStep) Name() string {
    return "ReserveInventory"
}

// 处理支付Saga步骤
type ProcessPaymentStep struct {
    paymentService PaymentService
}

func (s *ProcessPaymentStep) Execute(ctx context.Context, state map[string]interface{}) error {
    orderRequest := state["order_request"].(*CreateOrderRequest)
    orderID := state["order_id"].(string)
    
    payment, err := s.paymentService.ProcessPayment(ctx, &PaymentRequest{
        OrderID: orderID,
        Amount:  orderRequest.TotalAmount,
        Method:  orderRequest.PaymentMethod,
    })
    
    if err != nil {
        return err
    }
    
    state["payment_id"] = payment.ID
    return nil
}

func (s *ProcessPaymentStep) Compensate(ctx context.Context, state map[string]interface{}) error {
    paymentID := state["payment_id"].(string)
    return s.paymentService.RefundPayment(ctx, paymentID)
}

func (s *ProcessPaymentStep) Name() string {
    return "ProcessPayment"
}
```

#### 事件溯源实现
```go
// 事件溯源实现
package eventsourcing

import (
    "context"
    "encoding/json"
    "fmt"
    "time"
)

type Event interface {
    GetAggregateID() string
    GetEventType() string
    GetVersion() int
    GetTimestamp() time.Time
    GetData() interface{}
}

type BaseEvent struct {
    AggregateID string    `json:"aggregate_id"`
    EventType   string    `json:"event_type"`
    Version     int       `json:"version"`
    Timestamp   time.Time `json:"timestamp"`
    Data        []byte    `json:"data"`
}

func (e *BaseEvent) GetAggregateID() string { return e.AggregateID }
func (e *BaseEvent) GetEventType() string   { return e.EventType }
func (e *BaseEvent) GetVersion() int        { return e.Version }
func (e *BaseEvent) GetTimestamp() time.Time { return e.Timestamp }

func (e *BaseEvent) GetData() interface{} {
    var data interface{}
    json.Unmarshal(e.Data, &data)
    return data
}

// 事件存储接口
type EventStore interface {
    SaveEvents(ctx context.Context, aggregateID string, events []Event, expectedVersion int) error
    LoadEvents(ctx context.Context, aggregateID string) ([]Event, error)
    LoadEventsFromVersion(ctx context.Context, aggregateID string, version int) ([]Event, error)
}

// PostgreSQL事件存储实现
type PostgreSQLEventStore struct {
    db *sql.DB
}

func NewPostgreSQLEventStore(db *sql.DB) *PostgreSQLEventStore {
    return &PostgreSQLEventStore{db: db}
}

func (es *PostgreSQLEventStore) SaveEvents(ctx context.Context, aggregateID string, events []Event, expectedVersion int) error {
    tx, err := es.db.BeginTx(ctx, nil)
    if err != nil {
        return err
    }
    defer tx.Rollback()
    
    // 检查版本冲突
    var currentVersion int
    err = tx.QueryRowContext(ctx, 
        "SELECT COALESCE(MAX(version), 0) FROM events WHERE aggregate_id = $1", 
        aggregateID).Scan(&currentVersion)
    if err != nil && err != sql.ErrNoRows {
        return err
    }
    
    if currentVersion != expectedVersion {
        return fmt.Errorf("version conflict: expected %d, got %d", expectedVersion, currentVersion)
    }
    
    // 保存事件
    for _, event := range events {
        data, err := json.Marshal(event.GetData())
        if err != nil {
            return err
        }
        
        _, err = tx.ExecContext(ctx, `
            INSERT INTO events (aggregate_id, event_type, version, timestamp, data) 
            VALUES ($1, $2, $3, $4, $5)`,
            event.GetAggregateID(),
            event.GetEventType(),
            event.GetVersion(),
            event.GetTimestamp(),
            data,
        )
        if err != nil {
            return err
        }
    }
    
    return tx.Commit()
}

func (es *PostgreSQLEventStore) LoadEvents(ctx context.Context, aggregateID string) ([]Event, error) {
    rows, err := es.db.QueryContext(ctx, `
        SELECT event_type, version, timestamp, data 
        FROM events 
        WHERE aggregate_id = $1 
        ORDER BY version`, aggregateID)
    if err != nil {
        return nil, err
    }
    defer rows.Close()
    
    var events []Event
    for rows.Next() {
        var event BaseEvent
        event.AggregateID = aggregateID
        
        err := rows.Scan(&event.EventType, &event.Version, &event.Timestamp, &event.Data)
        if err != nil {
            return nil, err
        }
        
        events = append(events, &event)
    }
    
    return events, nil
}

// 聚合根基类
type AggregateRoot struct {
    ID            string
    Version       int
    UncommittedEvents []Event
}

func (ar *AggregateRoot) GetUncommittedEvents() []Event {
    return ar.UncommittedEvents
}

func (ar *AggregateRoot) ClearUncommittedEvents() {
    ar.UncommittedEvents = nil
}

func (ar *AggregateRoot) ApplyEvent(event Event) {
    ar.UncommittedEvents = append(ar.UncommittedEvents, event)
    ar.Version++
}

// 订单聚合根
type OrderAggregate struct {
    AggregateRoot
    UserID      string
    Items       []OrderItem
    Status      OrderStatus
    TotalAmount decimal.Decimal
    CreatedAt   time.Time
}

type OrderCreatedEvent struct {
    OrderID     string          `json:"order_id"`
    UserID      string          `json:"user_id"`
    Items       []OrderItem     `json:"items"`
    TotalAmount decimal.Decimal `json:"total_amount"`
    CreatedAt   time.Time       `json:"created_at"`
}

func (o *OrderAggregate) CreateOrder(userID string, items []OrderItem) error {
    if o.ID != "" {
        return errors.New("order already exists")
    }
    
    // 计算总金额
    totalAmount := decimal.Zero
    for _, item := range items {
        totalAmount = totalAmount.Add(item.Price.Mul(decimal.NewFromInt(int64(item.Quantity))))
    }
    
    // 创建事件
    event := &OrderCreatedEvent{
        OrderID:     generateOrderID(),
        UserID:      userID,
        Items:       items,
        TotalAmount: totalAmount,
        CreatedAt:   time.Now(),
    }
    
    o.applyOrderCreated(event)
    o.ApplyEvent(&BaseEvent{
        AggregateID: o.ID,
        EventType:   "OrderCreated",
        Version:     o.Version + 1,
        Timestamp:   time.Now(),
        Data:        mustMarshal(event),
    })
    
    return nil
}

func (o *OrderAggregate) applyOrderCreated(event *OrderCreatedEvent) {
    o.ID = event.OrderID
    o.UserID = event.UserID
    o.Items = event.Items
    o.TotalAmount = event.TotalAmount
    o.Status = OrderStatusPending
    o.CreatedAt = event.CreatedAt
}

// 从事件重建聚合
func (o *OrderAggregate) LoadFromHistory(events []Event) {
    for _, event := range events {
        switch event.GetEventType() {
        case "OrderCreated":
            var orderCreated OrderCreatedEvent
            json.Unmarshal(event.(*BaseEvent).Data, &orderCreated)
            o.applyOrderCreated(&orderCreated)
        case "OrderConfirmed":
            o.Status = OrderStatusConfirmed
        case "OrderCancelled":
            o.Status = OrderStatusCancelled
        }
        o.Version = event.GetVersion()
    }
}
```

---

## 服务间通信模式

### 🔄 **同步通信模式**

#### gRPC服务实现
```proto
// proto/user/user.proto
syntax = "proto3";

package user.v1;

option go_package = "github.com/company/ecommerce/proto/user/v1;userv1";

import "google/protobuf/timestamp.proto";
import "google/protobuf/empty.proto";
import "validate/validate.proto";

service UserService {
  rpc CreateUser(CreateUserRequest) returns (CreateUserResponse);
  rpc GetUser(GetUserRequest) returns (GetUserResponse);
  rpc UpdateUser(UpdateUserRequest) returns (UpdateUserResponse);
  rpc DeleteUser(DeleteUserRequest) returns (google.protobuf.Empty);
  rpc ListUsers(ListUsersRequest) returns (ListUsersResponse);
  rpc AuthenticateUser(AuthenticateUserRequest) returns (AuthenticateUserResponse);
}

message User {
  string id = 1;
  string email = 2 [(validate.rules).string.email = true];
  string name = 3 [(validate.rules).string.min_len = 1];
  string phone = 4;
  repeated string roles = 5;
  UserStatus status = 6;
  google.protobuf.Timestamp created_at = 7;
  google.protobuf.Timestamp updated_at = 8;
}

enum UserStatus {
  USER_STATUS_UNSPECIFIED = 0;
  USER_STATUS_ACTIVE = 1;
  USER_STATUS_INACTIVE = 2;
  USER_STATUS_SUSPENDED = 3;
}

message CreateUserRequest {
  string email = 1 [(validate.rules).string.email = true];
  string name = 2 [(validate.rules).string.min_len = 1];
  string password = 3 [(validate.rules).string.min_len = 8];
  string phone = 4;
  repeated string roles = 5;
}

message CreateUserResponse {
  User user = 1;
}

message GetUserRequest {
  string id = 1 [(validate.rules).string.min_len = 1];
}

message GetUserResponse {
  User user = 1;
}
```

```go
// internal/user/grpc_server.go
package user

import (
    "context"
    "log"
    
    "google.golang.org/grpc/codes"
    "google.golang.org/grpc/status"
    
    userv1 "github.com/company/ecommerce/proto/user/v1"
)

type GRPCServer struct {
    userv1.UnimplementedUserServiceServer
    service Service
}

func NewGRPCServer(service Service) *GRPCServer {
    return &GRPCServer{
        service: service,
    }
}

func (s *GRPCServer) CreateUser(ctx context.Context, req *userv1.CreateUserRequest) (*userv1.CreateUserResponse, error) {
    user := &User{
        Email:    req.Email,
        Name:     req.Name,
        Password: req.Password,
        Phone:    req.Phone,
        Roles:    req.Roles,
    }
    
    createdUser, err := s.service.CreateUser(ctx, user)
    if err != nil {
        log.Printf("Failed to create user: %v", err)
        return nil, status.Errorf(codes.Internal, "failed to create user: %v", err)
    }
    
    return &userv1.CreateUserResponse{
        User: s.toProtoUser(createdUser),
    }, nil
}

func (s *GRPCServer) GetUser(ctx context.Context, req *userv1.GetUserRequest) (*userv1.GetUserResponse, error) {
    user, err := s.service.GetUser(ctx, req.Id)
    if err != nil {
        if err == ErrUserNotFound {
            return nil, status.Errorf(codes.NotFound, "user not found")
        }
        log.Printf("Failed to get user: %v", err)
        return nil, status.Errorf(codes.Internal, "failed to get user: %v", err)
    }
    
    return &userv1.GetUserResponse{
        User: s.toProtoUser(user),
    }, nil
}

func (s *GRPCServer) toProtoUser(user *User) *userv1.User {
    return &userv1.User{
        Id:        user.ID,
        Email:     user.Email,
        Name:      user.Name,
        Phone:     user.Phone,
        Roles:     user.Roles,
        Status:    userv1.UserStatus(user.Status),
        CreatedAt: timestamppb.New(user.CreatedAt),
        UpdatedAt: timestamppb.New(user.UpdatedAt),
    }
}

// gRPC客户端封装
type GRPCClient struct {
    conn   *grpc.ClientConn
    client userv1.UserServiceClient
}

func NewGRPCClient(target string) (*GRPCClient, error) {
    conn, err := grpc.Dial(target, 
        grpc.WithTransportCredentials(insecure.NewCredentials()),
        grpc.WithUnaryInterceptor(grpc_retry.UnaryClientInterceptor(
            grpc_retry.WithCodes(codes.Unavailable, codes.DeadlineExceeded),
            grpc_retry.WithMax(3),
            grpc_retry.WithBackoff(grpc_retry.BackoffExponential(100*time.Millisecond)),
        )),
    )
    if err != nil {
        return nil, err
    }
    
    client := userv1.NewUserServiceClient(conn)
    
    return &GRPCClient{
        conn:   conn,
        client: client,
    }, nil
}

func (c *GRPCClient) CreateUser(ctx context.Context, user *User) (*User, error) {
    req := &userv1.CreateUserRequest{
        Email:    user.Email,
        Name:     user.Name,
        Password: user.Password,
        Phone:    user.Phone,
        Roles:    user.Roles,
    }
    
    resp, err := c.client.CreateUser(ctx, req)
    if err != nil {
        return nil, err
    }
    
    return c.fromProtoUser(resp.User), nil
}

func (c *GRPCClient) fromProtoUser(protoUser *userv1.User) *User {
    return &User{
        ID:        protoUser.Id,
        Email:     protoUser.Email,
        Name:      protoUser.Name,
        Phone:     protoUser.Phone,
        Roles:     protoUser.Roles,
        Status:    UserStatus(protoUser.Status),
        CreatedAt: protoUser.CreatedAt.AsTime(),
        UpdatedAt: protoUser.UpdatedAt.AsTime(),
    }
}

func (c *GRPCClient) Close() error {
    return c.conn.Close()
}
```

### 📨 **异步通信模式**

#### 基于Kafka的事件驱动架构
```go
// 事件发布器
package events

import (
    "context"
    "encoding/json"
    "fmt"
    "log"
    
    "github.com/Shopify/sarama"
)

type EventPublisher interface {
    Publish(ctx context.Context, topic string, event interface{}) error
    PublishBatch(ctx context.Context, events []EventMessage) error
    Close() error
}

type EventMessage struct {
    Topic string
    Key   string
    Event interface{}
}

type KafkaEventPublisher struct {
    producer sarama.SyncProducer
}

func NewKafkaEventPublisher(brokers []string) (*KafkaEventPublisher, error) {
    config := sarama.NewConfig()
    config.Producer.RequiredAcks = sarama.WaitForAll
    config.Producer.Retry.Max = 5
    config.Producer.Return.Successes = true
    config.Producer.Compression = sarama.CompressionSnappy
    
    producer, err := sarama.NewSyncProducer(brokers, config)
    if err != nil {
        return nil, err
    }
    
    return &KafkaEventPublisher{
        producer: producer,
    }, nil
}

func (p *KafkaEventPublisher) Publish(ctx context.Context, topic string, event interface{}) error {
    data, err := json.Marshal(event)
    if err != nil {
        return fmt.Errorf("failed to marshal event: %w", err)
    }
    
    msg := &sarama.ProducerMessage{
        Topic: topic,
        Value: sarama.StringEncoder(data),
    }
    
    // 如果事件有ID，使用作为分区键
    if eventWithID, ok := event.(interface{ GetID() string }); ok {
        msg.Key = sarama.StringEncoder(eventWithID.GetID())
    }
    
    partition, offset, err := p.producer.SendMessage(msg)
    if err != nil {
        return fmt.Errorf("failed to send message: %w", err)
    }
    
    log.Printf("Message sent to partition %d at offset %d", partition, offset)
    return nil
}

func (p *KafkaEventPublisher) PublishBatch(ctx context.Context, events []EventMessage) error {
    messages := make([]*sarama.ProducerMessage, 0, len(events))
    
    for _, eventMsg := range events {
        data, err := json.Marshal(eventMsg.Event)
        if err != nil {
            return fmt.Errorf("failed to marshal event: %w", err)
        }
        
        msg := &sarama.ProducerMessage{
            Topic: eventMsg.Topic,
            Key:   sarama.StringEncoder(eventMsg.Key),
            Value: sarama.StringEncoder(data),
        }
        
        messages = append(messages, msg)
    }
    
    return p.producer.SendMessages(messages)
}

func (p *KafkaEventPublisher) Close() error {
    return p.producer.Close()
}

// 事件消费器
type EventConsumer interface {
    Subscribe(topics []string, handler EventHandler) error
    Close() error
}

type EventHandler func(ctx context.Context, message *EventMessage) error

type KafkaEventConsumer struct {
    consumer      sarama.ConsumerGroup
    groupID       string
    eventHandlers map[string]EventHandler
    ctx           context.Context
    cancel        context.CancelFunc
}

func NewKafkaEventConsumer(brokers []string, groupID string) (*KafkaEventConsumer, error) {
    config := sarama.NewConfig()
    config.Consumer.Group.Rebalance.Strategy = sarama.BalanceStrategyRoundRobin
    config.Consumer.Offsets.Initial = sarama.OffsetOldest
    config.Consumer.Group.Session.Timeout = 10 * time.Second
    config.Consumer.Group.Heartbeat.Interval = 3 * time.Second
    
    consumer, err := sarama.NewConsumerGroup(brokers, groupID, config)
    if err != nil {
        return nil, err
    }
    
    ctx, cancel := context.WithCancel(context.Background())
    
    return &KafkaEventConsumer{
        consumer:      consumer,
        groupID:       groupID,
        eventHandlers: make(map[string]EventHandler),
        ctx:           ctx,
        cancel:        cancel,
    }, nil
}

func (c *KafkaEventConsumer) Subscribe(topics []string, handler EventHandler) error {
    consumerGroupHandler := &ConsumerGroupHandler{
        eventHandler: handler,
    }
    
    go func() {
        for {
            select {
            case <-c.ctx.Done():
                return
            default:
                if err := c.consumer.Consume(c.ctx, topics, consumerGroupHandler); err != nil {
                    log.Printf("Error consuming messages: %v", err)
                }
            }
        }
    }()
    
    return nil
}

func (c *KafkaEventConsumer) Close() error {
    c.cancel()
    return c.consumer.Close()
}

type ConsumerGroupHandler struct {
    eventHandler EventHandler
}

func (h *ConsumerGroupHandler) Setup(sarama.ConsumerGroupSession) error   { return nil }
func (h *ConsumerGroupHandler) Cleanup(sarama.ConsumerGroupSession) error { return nil }

func (h *ConsumerGroupHandler) ConsumeClaim(session sarama.ConsumerGroupSession, claim sarama.ConsumerGroupClaim) error {
    for message := range claim.Messages() {
        eventMsg := &EventMessage{
            Topic: message.Topic,
            Key:   string(message.Key),
        }
        
        // 反序列化事件数据
        if err := json.Unmarshal(message.Value, &eventMsg.Event); err != nil {
            log.Printf("Failed to unmarshal event: %v", err)
            continue
        }
        
        // 处理事件
        if err := h.eventHandler(session.Context(), eventMsg); err != nil {
            log.Printf("Failed to handle event: %v", err)
            continue
        }
        
        // 标记消息已处理
        session.MarkMessage(message, "")
    }
    
    return nil
}
```

---

## 微服务治理

### 🛡️ **容错和稳定性**

#### 熔断器模式实现
```go
// 熔断器实现
package circuitbreaker

import (
    "context"
    "errors"
    "sync"
    "time"
)

type State int

const (
    StateClosed State = iota
    StateHalfOpen
    StateOpen
)

type CircuitBreaker struct {
    mutex           sync.RWMutex
    state           State
    failureCount    int64
    successCount    int64
    lastFailureTime time.Time
    lastSuccessTime time.Time
    
    // 配置
    failureThreshold int64
    successThreshold int64
    timeout          time.Duration
    maxRequests      int64
}

type Config struct {
    FailureThreshold int64         // 失败阈值
    SuccessThreshold int64         // 成功阈值 (半开状态)
    Timeout          time.Duration // 超时时间
    MaxRequests      int64         // 半开状态最大请求数
}

func NewCircuitBreaker(config Config) *CircuitBreaker {
    return &CircuitBreaker{
        state:            StateClosed,
        failureThreshold: config.FailureThreshold,
        successThreshold: config.SuccessThreshold,
        timeout:          config.Timeout,
        maxRequests:      config.MaxRequests,
    }
}

func (cb *CircuitBreaker) Execute(fn func() (interface{}, error)) (interface{}, error) {
    if !cb.allow() {
        return nil, errors.New("circuit breaker is open")
    }
    
    result, err := fn()
    
    if err != nil {
        cb.onFailure()
        return nil, err
    }
    
    cb.onSuccess()
    return result, nil
}

func (cb *CircuitBreaker) allow() bool {
    cb.mutex.Lock()
    defer cb.mutex.Unlock()
    
    switch cb.state {
    case StateClosed:
        return true
    case StateOpen:
        if time.Since(cb.lastFailureTime) > cb.timeout {
            cb.state = StateHalfOpen
            cb.failureCount = 0
            cb.successCount = 0
            return true
        }
        return false
    case StateHalfOpen:
        return cb.successCount+cb.failureCount < cb.maxRequests
    default:
        return false
    }
}

func (cb *CircuitBreaker) onSuccess() {
    cb.mutex.Lock()
    defer cb.mutex.Unlock()
    
    cb.successCount++
    cb.lastSuccessTime = time.Now()
    
    if cb.state == StateHalfOpen && cb.successCount >= cb.successThreshold {
        cb.state = StateClosed
        cb.failureCount = 0
        cb.successCount = 0
    }
}

func (cb *CircuitBreaker) onFailure() {
    cb.mutex.Lock()
    defer cb.mutex.Unlock()
    
    cb.failureCount++
    cb.lastFailureTime = time.Now()
    
    if cb.state == StateClosed && cb.failureCount >= cb.failureThreshold {
        cb.state = StateOpen
    } else if cb.state == StateHalfOpen {
        cb.state = StateOpen
    }
}

func (cb *CircuitBreaker) GetState() State {
    cb.mutex.RLock()
    defer cb.mutex.RUnlock()
    return cb.state
}

// gRPC拦截器集成熔断器
func CircuitBreakerUnaryInterceptor(cb *CircuitBreaker) grpc.UnaryClientInterceptor {
    return func(ctx context.Context, method string, req, reply interface{}, cc *grpc.ClientConn, invoker grpc.UnaryInvoker, opts ...grpc.CallOption) error {
        _, err := cb.Execute(func() (interface{}, error) {
            return nil, invoker(ctx, method, req, reply, cc, opts...)
        })
        return err
    }
}

// HTTP客户端集成熔断器
type CircuitBreakerHTTPClient struct {
    client *http.Client
    cb     *CircuitBreaker
}

func NewCircuitBreakerHTTPClient(client *http.Client, cb *CircuitBreaker) *CircuitBreakerHTTPClient {
    return &CircuitBreakerHTTPClient{
        client: client,
        cb:     cb,
    }
}

func (c *CircuitBreakerHTTPClient) Do(req *http.Request) (*http.Response, error) {
    result, err := c.cb.Execute(func() (interface{}, error) {
        return c.client.Do(req)
    })
    
    if err != nil {
        return nil, err
    }
    
    return result.(*http.Response), nil
}
```

#### 限流器实现
```go
// 令牌桶限流器
package ratelimiter

import (
    "context"
    "sync"
    "time"
    
    "golang.org/x/time/rate"
)

type RateLimiter interface {
    Allow() bool
    Wait(ctx context.Context) error
    Reserve() *Reservation
}

// 令牌桶限流器
type TokenBucketRateLimiter struct {
    limiter *rate.Limiter
}

func NewTokenBucketRateLimiter(r rate.Limit, b int) *TokenBucketRateLimiter {
    return &TokenBucketRateLimiter{
        limiter: rate.NewLimiter(r, b),
    }
}

func (t *TokenBucketRateLimiter) Allow() bool {
    return t.limiter.Allow()
}

func (t *TokenBucketRateLimiter) Wait(ctx context.Context) error {
    return t.limiter.Wait(ctx)
}

func (t *TokenBucketRateLimiter) Reserve() *Reservation {
    reservation := t.limiter.Reserve()
    return &Reservation{reservation: reservation}
}

type Reservation struct {
    reservation *rate.Reservation
}

func (r *Reservation) OK() bool {
    return r.reservation.OK()
}

func (r *Reservation) Delay() time.Duration {
    return r.reservation.Delay()
}

func (r *Reservation) Cancel() {
    r.reservation.Cancel()
}

// 滑动窗口限流器
type SlidingWindowRateLimiter struct {
    mutex     sync.RWMutex
    requests  []time.Time
    limit     int
    window    time.Duration
    lastClean time.Time
}

func NewSlidingWindowRateLimiter(limit int, window time.Duration) *SlidingWindowRateLimiter {
    return &SlidingWindowRateLimiter{
        requests:  make([]time.Time, 0, limit),
        limit:     limit,
        window:    window,
        lastClean: time.Now(),
    }
}

func (s *SlidingWindowRateLimiter) Allow() bool {
    s.mutex.Lock()
    defer s.mutex.Unlock()
    
    now := time.Now()
    s.cleanOldRequests(now)
    
    if len(s.requests) >= s.limit {
        return false
    }
    
    s.requests = append(s.requests, now)
    return true
}

func (s *SlidingWindowRateLimiter) cleanOldRequests(now time.Time) {
    // 避免频繁清理
    if now.Sub(s.lastClean) < s.window/10 {
        return
    }
    
    cutoff := now.Add(-s.window)
    validIndex := 0
    
    for i, requestTime := range s.requests {
        if requestTime.After(cutoff) {
            validIndex = i
            break
        }
    }
    
    if validIndex > 0 {
        copy(s.requests, s.requests[validIndex:])
        s.requests = s.requests[:len(s.requests)-validIndex]
    }
    
    s.lastClean = now
}

// 分布式限流器 (基于Redis)
type DistributedRateLimiter struct {
    redis  RedisClient
    script string
}

func NewDistributedRateLimiter(redis RedisClient) *DistributedRateLimiter {
    script := `
        local key = KEYS[1]
        local limit = tonumber(ARGV[1])
        local window = tonumber(ARGV[2])
        local current_time = tonumber(ARGV[3])
        
        -- 清理过期的请求
        redis.call('ZREMRANGEBYSCORE', key, '-inf', current_time - window)
        
        -- 获取当前计数
        local current_count = redis.call('ZCARD', key)
        
        if current_count < limit then
            -- 添加当前请求
            redis.call('ZADD', key, current_time, current_time)
            redis.call('EXPIRE', key, window)
            return {1, limit - current_count - 1}
        else
            return {0, 0}
        end
    `
    
    return &DistributedRateLimiter{
        redis:  redis,
        script: script,
    }
}

func (d *DistributedRateLimiter) Allow(ctx context.Context, key string, limit int, window time.Duration) (bool, error) {
    now := time.Now().Unix()
    windowSeconds := int(window.Seconds())
    
    result, err := d.redis.Eval(ctx, d.script, []string{key}, limit, windowSeconds, now).Result()
    if err != nil {
        return false, err
    }
    
    values := result.([]interface{})
    allowed := values[0].(int64) == 1
    
    return allowed, nil
}
```

### 📊 **服务监控和观测**

#### 分布式追踪实现
```go
// OpenTelemetry集成
package tracing

import (
    "context"
    "log"
    
    "go.opentelemetry.io/otel"
    "go.opentelemetry.io/otel/attribute"
    "go.opentelemetry.io/otel/exporters/jaeger"
    "go.opentelemetry.io/otel/sdk/resource"
    "go.opentelemetry.io/otel/sdk/trace"
    semconv "go.opentelemetry.io/otel/semconv/v1.17.0"
    "go.opentelemetry.io/otel/trace"
)

func InitTracer(serviceName, jaegerEndpoint string) func() {
    exp, err := jaeger.New(jaeger.WithCollectorEndpoint(jaeger.WithEndpoint(jaegerEndpoint)))
    if err != nil {
        log.Fatal(err)
    }
    
    tp := trace.NewTracerProvider(
        trace.WithBatcher(exp),
        trace.WithResource(resource.NewWithAttributes(
            semconv.SchemaURL,
            semconv.ServiceName(serviceName),
            semconv.ServiceVersion("1.0.0"),
            attribute.String("environment", "production"),
        )),
        trace.WithSampler(trace.TraceIDRatioBased(0.1)), // 10% 采样率
    )
    
    otel.SetTracerProvider(tp)
    
    return func() {
        if err := tp.Shutdown(context.Background()); err != nil {
            log.Fatal(err)
        }
    }
}

// 服务间调用追踪
func TraceServiceCall(ctx context.Context, serviceName, operation string, fn func(context.Context) error) error {
    tracer := otel.Tracer("microservice-tracer")
    
    ctx, span := tracer.Start(ctx, fmt.Sprintf("%s.%s", serviceName, operation))
    defer span.End()
    
    span.SetAttributes(
        attribute.String("service.name", serviceName),
        attribute.String("operation.name", operation),
    )
    
    err := fn(ctx)
    if err != nil {
        span.SetStatus(codes.Error, err.Error())
        span.RecordError(err)
    } else {
        span.SetStatus(codes.Ok, "success")
    }
    
    return err
}

// 数据库查询追踪
func TraceDatabaseQuery(ctx context.Context, query string, args []interface{}, fn func() error) error {
    tracer := otel.Tracer("database-tracer")
    
    ctx, span := tracer.Start(ctx, "database.query")
    defer span.End()
    
    span.SetAttributes(
        attribute.String("db.system", "postgresql"),
        attribute.String("db.statement", query),
        attribute.Int("db.args.count", len(args)),
    )
    
    start := time.Now()
    err := fn()
    duration := time.Since(start)
    
    span.SetAttributes(
        attribute.Float64("db.duration.ms", float64(duration.Nanoseconds())/1e6),
    )
    
    if err != nil {
        span.SetStatus(codes.Error, err.Error())
        span.RecordError(err)
    } else {
        span.SetStatus(codes.Ok, "success")
    }
    
    return err
}

// HTTP客户端追踪
type TracingHTTPClient struct {
    client *http.Client
    tracer trace.Tracer
}

func NewTracingHTTPClient(client *http.Client) *TracingHTTPClient {
    return &TracingHTTPClient{
        client: client,
        tracer: otel.Tracer("http-client"),
    }
}

func (c *TracingHTTPClient) Do(req *http.Request) (*http.Response, error) {
    ctx, span := c.tracer.Start(req.Context(), fmt.Sprintf("HTTP %s", req.Method))
    defer span.End()
    
    span.SetAttributes(
        attribute.String("http.method", req.Method),
        attribute.String("http.url", req.URL.String()),
        attribute.String("http.scheme", req.URL.Scheme),
        attribute.String("http.host", req.URL.Host),
        attribute.String("http.target", req.URL.Path),
    )
    
    // 注入追踪上下文到请求头
    otel.GetTextMapPropagator().Inject(ctx, propagation.HeaderCarrier(req.Header))
    
    start := time.Now()
    resp, err := c.client.Do(req.WithContext(ctx))
    duration := time.Since(start)
    
    span.SetAttributes(
        attribute.Float64("http.duration.ms", float64(duration.Nanoseconds())/1e6),
    )
    
    if err != nil {
        span.SetStatus(codes.Error, err.Error())
        span.RecordError(err)
        return nil, err
    }
    
    span.SetAttributes(
        attribute.Int("http.status_code", resp.StatusCode),
        attribute.String("http.status_text", resp.Status),
    )
    
    if resp.StatusCode >= 400 {
        span.SetStatus(codes.Error, fmt.Sprintf("HTTP %d", resp.StatusCode))
    } else {
        span.SetStatus(codes.Ok, "success")
    }
    
    return resp, nil
}
```

---

## 实战项目实施

### 🚀 **电商微服务平台**

#### 项目架构图
```
                                Frontend Applications
                           ┌─────────────┬─────────────┬─────────────┐
                           │   Web App   │ Mobile App  │ Admin Panel │
                           └─────────────┴─────────────┴─────────────┘
                                              │
                           ┌─────────────────────────────────────────┐
                           │              API Gateway               │
                           │         (Kong / Custom)                │
                           └─────────────────┬───────────────────────┘
                                              │
            ┌─────────────────────────────────┼─────────────────────────────────┐
            │                                 │                                 │
    ┌───────▼──────┐              ┌──────────▼─────────┐              ┌────────▼──────┐
    │ User Services │              │ Product Services   │              │ Order Services │
    │               │              │                    │              │                │
    │ ┌───────────┐ │              │ ┌────────────────┐ │              │ ┌────────────┐ │
    │ │User Svc   │ │              │ │Product Svc     │ │              │ │Order Svc   │ │
    │ │Auth Svc   │ │◄─────────────┤ │Inventory Svc   │ │◄─────────────┤ │Cart Svc    │ │
    │ │Profile Svc│ │              │ │Category Svc    │ │              │ │Payment Svc │ │
    │ └───────────┘ │              │ │Search Svc      │ │              │ │Shipping Svc│ │
    └───────┬───────┘              │ └────────────────┘ │              │ └────────────┘ │
            │                      └──────────┬─────────┘              └────────┬───────┘
            │                                │                                 │
    ┌───────▼──────┐              ┌──────────▼─────────┐              ┌────────▼──────┐
    │   User DB    │              │   Product DB       │              │   Order DB    │
    │ (PostgreSQL) │              │ (PostgreSQL)       │              │ (PostgreSQL)  │
    └──────────────┘              │ + Redis Cache      │              │ + Redis       │
                                  │ + Elasticsearch    │              └───────────────┘
                                  └────────────────────┘
                                              │
                           ┌─────────────────────────────────────────┐
                           │              Message Bus               │
                           │              (Apache Kafka)            │
                           └─────────────────────────────────────────┘
                                              │
                           ┌─────────────────────────────────────────┐
                           │           Shared Services              │
                           │                                        │
                           │ ┌─────────────┬─────────────┬─────────┐ │
                           │ │Notification │ Analytics   │ Audit   │ │
                           │ │   Service   │  Service    │Service  │ │
                           │ └─────────────┴─────────────┴─────────┘ │
                           └─────────────────────────────────────────┘
```

#### 完整部署配置
```yaml
# namespace定义
apiVersion: v1
kind: Namespace
metadata:
  name: ecommerce
  labels:
    name: ecommerce
    istio-injection: enabled
---
# 用户服务部署
apiVersion: apps/v1
kind: Deployment
metadata:
  name: user-service
  namespace: ecommerce
  labels:
    app: user-service
    version: v1
spec:
  replicas: 3
  selector:
    matchLabels:
      app: user-service
      version: v1
  template:
    metadata:
      labels:
        app: user-service
        version: v1
      annotations:
        prometheus.io/scrape: "true"
        prometheus.io/port: "8080"
        prometheus.io/path: "/metrics"
    spec:
      serviceAccountName: user-service
      containers:
      - name: user-service
        image: ecommerce/user-service:v1.2.0
        ports:
        - containerPort: 8080
          name: http
        - containerPort: 9090
          name: grpc
        env:
        - name: DATABASE_URL
          valueFrom:
            secretKeyRef:
              name: user-db-secret
              key: url
        - name: REDIS_URL
          value: "redis://redis-cluster:6379"
        - name: KAFKA_BROKERS
          value: "kafka-0:9092,kafka-1:9092,kafka-2:9092"
        - name: JAEGER_ENDPOINT
          value: "http://jaeger-collector:14268/api/traces"
        - name: SERVICE_NAME
          value: "user-service"
        resources:
          requests:
            memory: "256Mi"
            cpu: "200m"
          limits:
            memory: "512Mi"  
            cpu: "500m"
        livenessProbe:
          httpGet:
            path: /health
            port: 8080
          initialDelaySeconds: 30
          periodSeconds: 10
          timeoutSeconds: 5
          failureThreshold: 3
        readinessProbe:
          httpGet:
            path: /ready
            port: 8080
          initialDelaySeconds: 5
          periodSeconds: 5
          timeoutSeconds: 3
          failureThreshold: 3
        volumeMounts:
        - name: config
          mountPath: /app/config
          readOnly: true
      volumes:
      - name: config
        configMap:
          name: user-service-config
---
# 用户服务Service
apiVersion: v1
kind: Service
metadata:
  name: user-service
  namespace: ecommerce
  labels:
    app: user-service
spec:
  selector:
    app: user-service
  ports:
  - port: 8080
    targetPort: 8080
    name: http
  - port: 9090
    targetPort: 9090
    name: grpc
---
# 用户服务配置
apiVersion: v1
kind: ConfigMap
metadata:
  name: user-service-config
  namespace: ecommerce
data:
  config.yaml: |
    server:
      http_port: 8080
      grpc_port: 9090
      shutdown_timeout: 30s
    
    database:
      max_open_conns: 25
      max_idle_conns: 5
      conn_max_lifetime: 5m
    
    cache:
      ttl: 5m
      max_entries: 10000
    
    auth:
      jwt_secret: ${JWT_SECRET}
      token_expiry: 24h
    
    rate_limiting:
      requests_per_second: 100
      burst: 200
    
    circuit_breaker:
      failure_threshold: 5
      success_threshold: 3
      timeout: 60s
---
# Istio VirtualService
apiVersion: networking.istio.io/v1beta1
kind: VirtualService  
metadata:
  name: user-service
  namespace: ecommerce
spec:
  hosts:
  - user-service
  http:
  - match:
    - uri:
        prefix: /api/v1/users
    route:
    - destination:
        host: user-service
        port:
          number: 8080
    timeout: 30s
    retries:
      attempts: 3
      perTryTimeout: 10s
      retryOn: gateway-error,connect-failure,refused-stream
---
# Istio DestinationRule
apiVersion: networking.istio.io/v1beta1
kind: DestinationRule
metadata:
  name: user-service
  namespace: ecommerce
spec:
  host: user-service
  trafficPolicy:
    connectionPool:
      tcp:
        maxConnections: 100
      http:
        http1MaxPendingRequests: 100
        maxRequestsPerConnection: 10
    circuitBreaker:
      consecutiveErrors: 3
      intervalSeconds: 30
      baseEjectionTimeSeconds: 30
      maxEjectionPercent: 50
    loadBalancer:
      simple: LEAST_CONN
  subsets:
  - name: v1
    labels:
      version: v1
---
# HPA自动扩缩容
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: user-service-hpa
  namespace: ecommerce
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: user-service
  minReplicas: 3
  maxReplicas: 20  
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70
  - type: Resource
    resource:
      name: memory
      target:
        type: Utilization
        averageUtilization: 80
  behavior:
    scaleUp:
      stabilizationWindowSeconds: 300
      policies:
      - type: Percent
        value: 100
        periodSeconds: 15
      - type: Pods
        value: 4
        periodSeconds: 15
      selectPolicy: Max
    scaleDown:
      stabilizationWindowSeconds: 300
      policies:
      - type: Percent
        value: 10
        periodSeconds: 60
```

### ✅ **验收标准**

完成本章学习后，你应该能够：

**微服务设计能力**:
- [ ] 根据业务领域合理拆分微服务
- [ ] 设计松耦合、高内聚的服务边界
- [ ] 实现有效的服务间通信机制
- [ ] 处理分布式系统的数据一致性问题

**架构实现能力**:
- [ ] 配置和管理API网关
- [ ] 实现服务发现和负载均衡
- [ ] 建立事件驱动架构
- [ ] 实施Saga模式和事件溯源

**治理和运维能力**:
- [ ] 实现熔断、限流、重试机制
- [ ] 建立分布式追踪体系
- [ ] 配置服务监控和告警
- [ ] 进行微服务部署和扩缩容

**项目交付能力**:
- [ ] 完成完整的微服务电商平台
- [ ] 实现服务的自动化部署
- [ ] 建立服务质量监控体系
- [ ] 具备复杂问题的故障排查能力

---

*下一章: [云原生技术栈](./云原生技术栈.md)*